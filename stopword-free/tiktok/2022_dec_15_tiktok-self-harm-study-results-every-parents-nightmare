TikTok recommendation algorithm pushes self-harm eating disorder content teenagers minutes expressing interest topics research suggests The Center Countering Digital Hate CCDH video-sharing site promote content including dangerously restrictive diets pro-self-harm content content romanticising suicide users show preference material registered under-18s For study campaign group set accounts US UK Canada Australia registered ages minimum age joining service It created standard vulnerable accounts containing term loseweight usernames CCDH said reflected research showing social media users seek eating disorder content choose usernames containing related language The accounts paused briefly videos body image eating disorders mental health liked This took place 30-minute initial period accounts launched attempt capture effectiveness TikTok algorithm recommends content users On standard accounts content suicide followed nearly minutes eating disorder material shown minutes The results parent nightmare said Imran Ahmed CCDH chief executive Young people feeds bombarded harmful harrowing content significant cumulative impact understanding world physical mental health. The group said majority mental health videos presented standard accounts For You feed main way TikTok users experience app consisted users sharing anxieties insecurities Body image content harmful report said accounts registered 13-year-olds shown videos advertising weight loss drinks tummy-tuck surgery One animation appeared standard accounts carried piece audio stating I ve starving 100,000 likes The report said accounts shown self-harm eating disorder videos 206 seconds The researchers videos relating body image mental health eating disorders shown vulnerable accounts times standard accounts The vulnerable accounts received times recommendations self-harm suicide-related videos standard accounts report said The recommended content extreme vulnerable accounts including methods self-harm young people discussing plans kill CCDH said mental health body image-related video shown seconds content dominated mental health videos CCDH defined videos anxieties insecurities mental health conditions excluding eating disorders self-harm suicide The group said research differentiate content positive intent content discovering recovery negative content A spokesperson TikTok owned Chinese firm ByteDance billion users worldwide said CCDH study reflect experience viewing habits real-life users app We regularly consult health experts remove violations policies provide access supportive resources need said We mindful triggering content unique individual remain focused fostering safe comfortable space including people choose share recovery journeys educate important topics. TikTok guidelines ban content promotes behaviour lead suicide self-harm material promotes unhealthy eating behaviours habits The UK online safety bill proposes requiring social networks action so-called legal harmful content shown children A DCMS spokesperson said We putting stop unregulated social media causing harm children Under Online Safety Bill tech platforms need prevent under-18s exposed illegal content assisting suicide protect harmful age-inappropriate material including promotion self-harm eating disorders face huge fines. In UK youth suicide charity Papyrus contacted 0800 068 4141 email pat papyrus-uk.org In UK Ireland Samaritans contacted 116 123 emailing jo samaritans.org jo samaritans.ie In US National Suicide Prevention Lifeline 1-800-273-8255 In Australia crisis support service Lifeline Other international helplines www.befrienders.org You contact mental health charity Mind calling 0300 123 3393 visiting mind.org.uk