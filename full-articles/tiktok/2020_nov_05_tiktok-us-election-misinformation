TikTok has emerged as an unexpected source of misinformation about the US election, with numerous inaccurate or misleading posts circulating as tech companies battle to contain falsehoods from Donald Trump and others. “TikTok has in the past been a breeding ground for false reports that spread peer to peer,” said Angelo Carusone, the president of Media Matters and an expert on rightwing extremism and misinformation.   Related: Facebook removes pro-Trump Stop the Steal group over 'calls for violence'    The report identified 11 examples of election misinformation on Wednesday that racked up more than 200,000 combined views before TikTok removed them. On Thursday, it found that videos pushing a Qanon-related conspiracy theory about ballots went viral, amassing more than 200,000 views in just a few hours before TikTok removed them for violating its misinformation policy. Misinformation in these videos included false narratives that claimed ballots being counted for Joe Biden were fraudulent, and that poll workers were handing out markers to Trump voters so their votes would go uncounted. Some of the content originated from young Republican influencers on TikTok: two pro-Trump pages called Republican Hype House and The Republican Boys echoed Trump’s rhetoric in claiming the election was being stolen. TikTok cracked down on the accounts, flagging some of the videos and leading one of the accounts to post an apology on Wednesday, promising to post less frequently to ensure it does not get deplatformed by TikTok. “We’re working diligently to protect the integrity of our platform as the election cycle continues,” TikTok said in a statement. “We’re removing election misinformation as it’s identified – proactively through automated technology and human investigations, and reactively via reports from our users and partners.” The company removed almost all 15 videos mentioned in both reports and has been cracking down on other sources of misinformation. It did not remove one video, but rather reduced its reach and added a banner linking to correct information. Despite these viral examples, the video-sharing platform is the newest of the major social media firms and is doing relatively well given its inexperience, Carusone said. This may be in part because, compared with Facebook and Twitter, TikTok was initially seen less as a forum for political news and discussion and more as a space to share funny videos. “I think it is worth focusing on these individual examples, even if they are not representative of the entire platform as a whole, because what they do is identify gaps in the preventative measures that the platform has,” Carusone said. Meanwhile, Twitter has flagged or removed content with misinformation referencing election results before they are released – including tweets from Trump. It has also reduced the reach of flagged tweets and eliminated algorithmic recommendations like trending topics to minimize the spread of misinformation. Facebook, similarly, is flagging posts in which the president or others call the election before reputable sources have. On Thursday Facebook shut down a group being used to organize in support of stopping the count of votes in key states.     Sign up for the Guardian’s First Thing newsletter 