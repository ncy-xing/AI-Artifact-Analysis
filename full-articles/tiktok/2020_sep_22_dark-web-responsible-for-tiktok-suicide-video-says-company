A graphic suicide video that went viral on TikTok in early September was the result of a coordinated raid from the dark web the company has told MPs. Giving evidence to the Commons committee for digital culture media and sport (DCMS) Theo Bertram TikTok's European director of public policy said the video which was originally broadcast live on Facebook was used in a coordinated attack on the social video app a week after it was originally recorded. We learned that groups operating on the dark web made plans to raid social media platforms including TikTok in order to spread the video across the internet Bertram said. What we saw was a group of users who were repeatedly attempting to upload the video to our platform and splicing it editing it cutting it in different ways he added. I don't want to say too much publicly in this forum about how we detect and manage that but our emergency machine-learning services kicked in and they detected the videos. The death was widely shared on the site with prominent users eventually sharing advice to others on how to spot and avoid the video before it autoplayed. Almost a week separated the death from the raid on TikTok which has led the company to propose a global coalition to help protect users against such harmful content. Last night we wrote to the CEOs of Facebook Instagram Google YouTube Twitter Twitch Snapchat Pinterest and Reddit Bertram said and what we are proposing is that in the same way these companies already work together around [child sexual abuse imagery] and terrorist-related content we should now establish a partnership around dealing with this type of content. Such a partnership would have allowed for instance Facebook to share technical details of the graphic video so that TikTok could prevent it from being uploaded in the first place. That would also ease the burden on moderation for the smaller companies. In the UK TikTok has 363 moderators Bertram revealed out of a staff of 800.   Related TikTok why it is being sold and who will own it    As well as working on keeping the platform clean of harmful content those moderators are also tasked with enforcing TikTok's age guidelines Every time you moderate a video with a human reviewer that human reviewer whatever else they're reviewing that video for is also looking to see whether that account belongs to someone under the age of 13 Bertram revealed. If the account looks like it does belong to someone underage it is removed. Bertram also asked MPs to help simplify that process by requiring Apple and Google to incorporate stronger age restrictions into their app stores. There are only two app stores he argued. So if you said to the app stores This is the one place where we're going to ask parents to give proof of ageâ€™ then you're not increasing the risk of the data loss by making parents get out data for every app but you can ensure that every app then needs to verify the age with that app store. It seems to me that that would be a solution to a tougher age verification. Responding to a complaint from the Tory MP Steve Brine about trashy content on the app such as content where there's a mother and daughter pushing their tushy if you know what I mean Bertram recommended MPs follow Andrew Lloyd Webber's videos. Does he push his tushy Brine asked. Bertram confirmed that no Andrew Lloyd Webber does not but he is quite entertaining.  In the UK and Ireland Samaritans can be contacted on 116 123 or email jo@samaritans.org or jo@samaritans.ie. In the US the National Suicide Prevention Lifeline is 1-800-273-8255. In Australia the crisis support service Lifeline is 13 11 14. Other international helplines can be found at www.befrienders.org.