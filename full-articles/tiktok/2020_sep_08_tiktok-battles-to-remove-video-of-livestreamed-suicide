TikTok is battling to remove a graphic video of a livestreamed suicide, after the footage was uploaded to the service on Sunday night from Facebook, where it was initially broadcast. Although the footage was rapidly taken down from TikTok, users spent much of Monday re-uploading it, initially unchanged, but later incorporated into so-called bait-and-switch videos, which are designed to shock and upset unsuspecting users. One such video, for instance, begins with a conventional video of an influencer talking to camera, before cutting without warning to the graphic footage. Some TikTok users began warning their followers to look out for the opening frames of the video, which feature a man with long hair and a grey beard, and instantly scroll away if they see the footage. But many reported being curious about the footage as a result, and seeking it out, only to be left distraught and upset by what they saw. TikTok confirmed that it is taking down the footage as it finds it. “On Sunday night, clips of a suicide that had originally been livestreamed on Facebook circulated on other platforms, including TikTok,” a spokesperson said.   Related: TikTok video: Australian PM says distressing suicide footage must be removed    “Our systems, together with our moderation teams, have been detecting and blocking these clips for violating our policies against content that displays, praises, glorifies, or promotes suicide. We are banning accounts that repeatedly try to upload clips, and we appreciate our community members who’ve reported content and warned others against watching, engaging, or sharing such videos on any platform out of respect for the person and their family. “If anyone in our community is struggling with thoughts of suicide or concerned about someone who is, we encourage them to seek support, and we provide access to hotlines directly from our app and in our Safety Center.” Such shock imagery has been a regular problem for many social networks, but the power and popularity of TikTok’s algorithmic feed – the “for you” page – means that users can be exposed to such content even if no one they follow on the site chooses to share or engage with it. The video’s initial spread on TikTok has led to versions saved from the app spreading to other messaging services, including WhatsApp. One parent said their child had seen the footage in a WhatsApp group set up for 11-year-olds to communicate with their new secondary school classmates, and was left “very disturbed”.  In the UK and Ireland, Samaritans can be contacted on 116 123 or email jo@samaritans.org or jo@samaritans.ie. In the US, the National Suicide Prevention Lifeline is 1-800-273-8255. In Australia, the crisis support service Lifeline is 13 11 14. Other international helplines can be found at www.befrienders.org. 