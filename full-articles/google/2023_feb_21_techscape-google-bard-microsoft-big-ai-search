Search engines have been a major part of our online experience since the early 1990s when the booming growth of the world wide web created a need to sort and present information in response to user queries. The first users to traverse the information superhighway had a simple job of it. It was akin to pootling along to your local supermarket you knew the roads where to turn off and how to get there. But the exponential growth of the web meant that it quickly became impossible for people to remember where they'd found that pertinent bit of information they wanted. The main road became ensnared in a spider's web of byways. New crossings roundabouts and turnoffs appeared. Streets you'd driven along for ages led to dead ends. Others changed course. Search engines solved that by trying to categorise information based on queries you sent. Initially they were bad. Thanks to Google and a new way of crawling and categorising the web they quickly became very good. In the year 2000 Google became the world's largest search engine. The company became synonymous with search. We now Google things rather than search for them just as we hoover rather than vacuum. Except now in 2023 Google may no longer be synonymous with search. The rise of ChatGPT the revolutionary large language model (LLM) that can talk to users which I spoke about on the Guardian's Today in Focus podcast has been so significant and quick since its November 2022 release that it has thrown the future of search into flux. Microsoft has invested $10bn into ChatGPT's creator OpenAI and in return has the rights to use a souped-up version of the technology in its search engine Bing. In response Google has announced its own chat-enabled search tool named Bard designed to head off the enemy at the gates. Neither work particularly well it seems. Both made embarrassingly rudimentary mistakes in their much-hyped public demos and I've had access to the ChatGPT version of Bing whose codename is Sydney as some enterprising hackers got the chatbot to divulge for about a week. I wasn't unimpressed as this account of my time with Sydney so far shows but I also didn't really see the point. LLMs are a technology that has some annoying foibles when used in search like confidently making things up when it doesn't know the answer to a question that don't seem to mesh well with what we use Google and others for. For now it looks like Google and Microsoft will shove chat-enabled search engines down our throats because they want the kudos of being first to this technology. But my main question is whether it'll stick. (Microsoft appears to be having second thoughts about the rollout already on Friday it limited the length of interactions with Sydney after the chatbot showed a tendency to express infatuation for those it conversed with for hours.) I still think that we're in the most interesting time for search since Google became the 500lb gorilla in the room back in the late 1990s. I just don't know if the way we're using the chat functionality now will necessarily be how we use it in the future. I think ChatGPT is good for complex queries that there's no direct answers and summaries would be very beneficial William Wang director of the Centre for Responsible Machine Learning at the University of California Santa Barbara tells me. Simple queries definitely no need for ChatGPT. Wang believes the interface we see right now is just the start and things will get better quickly. Others aren't sure if search is the right use case for chat-based LLMs. Thinking of them as a new form of search is just wrong says Julian Togelius associate professor in AI at New York University. Togelius recommends that we take the decision on how the technology is used out of the hands of AI researchers or tech executives and into the hands of ordinary users to see what they develop. It's a subversion of the old phrase come and they will build. If you want to read the complete version of the newsletter please subscribe to receive TechScape in your inbox every Tuesday