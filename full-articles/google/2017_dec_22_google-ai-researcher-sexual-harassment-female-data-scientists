Katherine Heller felt helpless. The Duke University professor was at a statistics conference last year when, she said, she witnessed Steven Scott, a senior artificial intelligence (AI) researcher at Google, make sexual advances on one of her female students. 
According to Heller, when she spoke to Scott later at an event dinner, he was defensive and told the professor that she should be nice to him considering that he had secured her a Google-funded faculty research award. 
  
  
   
    
    Artificial Intelligence has various definitions, but in general it means a program that uses data to build a model of some aspect of the world. This model is then used to make informed decisions and predictions about future events. The technology is used widely, to provide speech and face recognition, language translation, and personal recommendations on music, film and shopping sites. In the future, it could deliver driverless cars, smart personal assistants, and intelligent energy grids. AI has the potential to make organisations more effective and efficient, but the technology raises serious issues of ethics, governance, privacy and law. 
    
   
  
  
 
“It was pretty shocking that he would say something like that,” said Heller, 38, who alleged that Scott had also tried to kiss her in an elevator at a conference in 2010, forcing her to push him off. “It was disturbing what had happened to my student. It was a worst nightmare situation for me as a female adviser to a female student.”  
The day after the incident, Heller said her student was distraught and talked about dropping out of the field for the first time. Given that Scott was not employed by her university, Heller didn’t know how she could report his behavior.  
 
  
  Katherine Heller. Photograph: Courtesy of Katherine Heller 
  
 
Last week, following sexual harassment and groping allegations by another woman in data science, Google suspended Scott. The episode marks the latest sexual misconduct controversy to hit the tech sector and academia at a time when women in Silicon Valley, entertainment and media are publicly speaking out in record numbers, bolstered by the viral #MeToo campaign.  
The allegations against Scott, who declined to comment, has shone a harsh light on harassment in the male-dominated field of statistics, data science and machine learning. Some said misconduct was common – especially at conferences that blend professional work with socializing – and that serial harassers rarely face consequences.  
In some cases, sexual misconduct has pushed women out of the field altogether. Beyond the personal devastation, there is long-term damage for machine learning and AI, a sector that is dramatically reshaping society, sometimes with powerful technology plagued by harmful biases.  
Women have been sharing stories in the wake of a blogpost by Kristian Lum, a statistician at the Human Rights Data Analysis Group. In an interview, Lum said she hoped her story would help other women come forward. 
“I can’t spend the rest of my life going around trying to block people who I know are bad actors,” said Lum, 33. “It does take an emotional toll … What we really need is a broader conversation and culture change.”  
 
  
  S repeatedly grabbed me under the water, putting his hands on my torso, hips, and thighs 
   Kristian Lum 
   
  
 
Lum’s post did not name Scott, but Bloomberg and other sources have confirmed that he is the man identified as “S” in her story. A Google spokeswoman also confirmed Scott’s suspension.  
In her viral Medium post, Lum said S was the “worst offender” in the field and that at a 2010 conference, he befriended her and a friend “acting interested in our research”. But while swimming with a group of conference participants, she wrote, “S repeatedly grabbed me under the water, putting his hands on my torso, hips, and thighs”. 
He picked her up and carried her away, she continued: “I struggled, gently at first and then more forcefully, and he let me go.” Others were targeted, she said: “He relentlessly pressured my friend, a female graduate student, to have sex with him.” 
At a Google reception a few years later, S stood behind Lum and talked loudly about “banging smokin’ hot chicks”, and when she gave him a look, “he replied that I was just jealous that he wasn’t talking about me”, she wrote. 
 
  
  Kristian Lum. Photograph: Picasa/Courtesy of Kristian Lum 
  
 
After the alleged groping incident in 2010, she said she became increasingly frustrated with the culture that condones this kind of behavior, contributing to her decision to leave academia. 
“I really felt embarrassed by the whole thing,” she said in an interview, adding: “There certainly was a critical mass of people who did know, and really nothing was being done about any of this.”  
Scott declined to respond to a detailed list of allegations, citing Google’s ongoing investigation.  
In her post, Lum also said a professor had recently made an offensive joke about sexual assault and had sent her Facebook messages, referencing sex and porn. He was later identified as Bradley Carlin, a University of Minnesota biostatistics professor, who sent an apology about his “ill-considered joke” to the Guardian and declined to comment further pending a university investigation.  
‘We are losing role models’ 
Since she published her story, Lum said she had heard from many women with similar stories and several who said they left the field or were considering leaving due to harassment. 
Heller said that she was anxious to even report Scott to her university, even though there was little the school could do about a researcher at a private company. 
“I was worried about what consequences this could have for my career. And that’s nothing compared to what consequences this could have for my student’s career,” she said, adding that although some women are now feeling more emboldened to speak up, “a lot of people are still scared to come forward”. 
 
  
  The system is so broken. So much more of the onus is placed on the victim than the harasser 
   ​Amy Cho 
   
  
 
Lum is well aware of the importance of diversity in her field. She has researched predictive policing programs, exposing how flawed data and AI can replicate and exacerbate racially biased law enforcement practices. 
“We are losing role models for the next generation of women,” she added. “Anytime you are losing a researcher, you are losing whatever advances they could’ve made.” 
Algorithms have also suffered from gender biases. It was recently revealed that Google Translate was producing sexist results by automatically matching male pronouns to certain professions and traits. 
Amy Cho, co-founder of an education startup that is using AI, said she quit a previous tech job due to sexual harassment and HR’s lack of response. 
“The system is so broken. So much more of the onus is placed on the victim than the harasser.”  
Vulnerable graduate students may choose not to report mistreatment at all and instead leave the field, said Lisa Lendway, a Macalester College statistics professor.  
“It’s hard enough to go through a program. To have that on top of it, I probably would’ve just quit.” 
Contact the author: sam.levin@theguardian.com