Google scientists have created a computer program that uses basic reasoning to learn to navigate the London Underground system by itself. The same Artificial Intelligence (AI) agent could also answer questions about the content of snippets of stories and work out family relationships by looking at a family tree. Scientists predict that in future a similar approach could pave the way for virtual assistants that would be able to instantaneously scour the internet to answer questions and carry out instructions with precision. Herbert Jaegar, a computer scientist at the University of Bremen, said: “I think this can be described as rational reasoning. They [the tasks] involve planning and structuring information into chunks and re-combining them.” Although the tasks themselves were fairly simple - a basic smartphone app can navigate a tube map - the way in which the program achieved its results is seen as impressive. It is one of the first programs to combine an external memory with an approach called deep-learning, in which the program learns how to do tasks independently rather than being pre-programmed with a set of rules by a human. Prof Geoff Hinton, a British scientist regarded as the father of deep learning, said the door was now open for deep learning to be applied to more complex tasks than many had originally thought possible. “Until very recently, it was far from obvious how deep learning could be used to allow a system to acquire the algorithms needed for conscious deliberate reasoning,” said Hinton, who works at the University of Toronto and Google. Deep learning has recently stormed ahead of other computing strategies in tasks like language translation, image and speech recognition and even enabled a computer to beat top-ranked player, Lee Sedol, at Go. However, until now the technique has generally performed poorly on any task where an overarching strategy is needed, such as navigation or extracting the actual meaning from a text. The latest program achieved this by adding an external memory, designed to temporarily store important pieces of information and fish them out when needed. The human equivalent of this is working memory, a short-term repository in the brain that allows us to stay on task when doing something that involves several steps, like following a recipe. Alex Graves, the research scientist at Google DeepMind in London who led the work, said that the work marked an incremental step towards smart machines, rather than a sudden departure. “I’m wary of saying now we have a machine that can reason,” he said. “We have something that has an improved memory - a different kind of memory that we believe is a necessary component of reasoning. It’s hard to draw a line in the sand.” In the study, published in the journal Nature, the program was able to find the quickest route between underground stops and work out where it would end up if it travelled, say, two stops north from Victoria station.  It was also given story snippets, such as “John is in the playground. John picked up the football.” followed by the question “Where is the football?” and was able to answer correctly, hinting that in future assistants such Apple’s Siri may be replaced by something more sophisticated. Graves said that while the story tasks “look so trivial to a human that they don’t seem like questions at all,” existing computer programs “do really badly on this”. The program he developed got questions like this right 96% of the time. Jaegar said that the latest effort by DeepMind should be viewed as “just one hop forward in what should be described as a stampede” of rapidly unfolding developments in AI, adding that the abilities of computers would not necessarily be restricted to logical tasks such as navigation in future.  “Why should there be an inherent limit? Everything that a brain can do is possible with a physical system,” he said. “They [computers] will come closer to performance and are already even better on some things. It’s a matter of time and of funding: whether anyone will be willing to spend the necessary millions to develop these things.” A number of high profile scientists have warned about the existential threat posed by AI, with Stephen Hawking cautioning that “once humans develop artificial intelligence, it will take off on its own and redesign itself at an ever-increasing rate”. But Demis Hassabis, the founder of DeepMind has previously played down such concerns. “We’re decades away from any sort of technology that we need to worry about,” Hassabis said last year.