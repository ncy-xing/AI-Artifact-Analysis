The battle for the future of computing is a battle to bring artificial intelligence to the mainstream – and Google is quietly overhauling a machine learning tool used to improve some of its most popular services including Google Translate and Google Photos. TensorFlow can be used to help teach computers how to process data in ways similar to how the human brain handles information. It is also open source, meaning Google has published and shared the code online so that external developers can use and improve it. The latest version, released by Google on Wednesday, adds a feature many TensorFlow users have asked for since the tool made its public debut in late 2015: the ability to operate on multiple devices.  Instead of being limited by the processing capabilities of a single computer, it can use distributed networks to handle more complicated tasks – as if TensorFlow will now be able to use many brain cells instead of being confined to just one. TensorFlow was developed to improve many of the services Google users interact with on a regular basis. It has taught the translation app to understand more of language’s idiosyncrasies, allowed the photos tool to identify many of the subjects in the images uploaded to its servers and made it easier for Google’s mobile apps to understand what people are saying when giving verbal instructions to its search engine. Humans already excel at those tasks. Most people can tell a cat from a dog, think beyond literal translations and follow a conversation as they walk along a crowded street. The human brain simply knows how to do those things.  But computers can struggle to do the same; that’s why tools such as TensorFlow are used to help these devices perceive and process the world by emulating the neural networks inside our heads. Google previously used a tool called DistBelief to perform many of the same tasks. TensorFlow was developed to improve on DistBelief’s performance and – according to Google’s chief executive, Sundar Pichai – is up to five times faster than its predecessor. Many of the improvements made to Google’s services over the last year can be at least partly attributed to the switch from DistBelief to TensorFlow during that period. Matthew Zeiler was an intern on the DistBelief project, and has since founded the visual AI service Clarifai, based in New York. “We’re building a platform that allows computers to see, essentially, and allows developers to include these applications on their own websites.”  Clarifai is being used by Vimeo to improve video search, by BuzzFeed to manage its continually growing media collection and by travel site Trivago to automatically label photos that contain an ocean view, or show a bedroom or a living room. “Neural nets are getting used everywhere these days.” “It’s very important to be able to train quickly … if you can split workers working on different chunks of data and have them communicate and synchronize that data between nodes, it allows them to learn more efficiently.” “Deep learning is a huge opportunity right now because it enables developers to create applications in a way that was never possible before. Neural networks are a new way of programming computers … It’s a new way of handling data.” TensorFlow was made available to the public on 9 November. It was a quick hit among developers and became the most popular project on GitHub, a platform where software engineers learn from and collaborate with each other, for 2015 even though it was only available for the last two months of the year.  Those improvements will eventually reach ordinary people through Google’s everyday products – even if it isn’t immediately obvious why a service suddenly became much smarter and more accurate.